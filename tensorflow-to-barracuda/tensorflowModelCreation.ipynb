{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "import tensorflow_to_barracuda as tf2bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.Session(config=generate_session_config(), graph=graph)\n",
    "\n",
    "with graph.as_default():\n",
    "    #theses constants are necessary for our model to be interpreted by Barracuda\n",
    "    tf.Variable(2, name=\"version_number\", trainable=False, dtype=tf.int32)\n",
    "    tf.Variable(0, name=\"memory_size\", trainable=False, dtype=tf.int32)\n",
    "    tf.Variable(0, name=\"is_continuous_control\", trainable=False, dtype=tf.int32)\n",
    "    tf.Variable(sum(action_size), name=\"action_output_shape\", trainable=False, dtype=tf.int32)\n",
    "    #action_size is an array containing as much elements as there are branches of actions. \n",
    "    #Each element describes the number of actions possible for a certain branch.\n",
    "    \n",
    "    mask_input = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"action_masks\")\n",
    "    \n",
    "    action_idx = [0] + list(np.cumsum(action_size))\n",
    "    branch_masks = [mask_input[:, action_idx[i] : action_idx[i + 1]] for i in range(len(action_size))]\n",
    "    \n",
    "    in_ph = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"vector_observation\")\n",
    "    h1_layer = tf.layers.dense(in_ph, 16, None)\n",
    "    branch1_layer = tf.layers.dense(h1_layer, 2, activation=None) #branch 1 has two actions so we put 2 units at the end of this branch\n",
    "    #should do a for-loop over action_size, to create X branch layer\n",
    "\n",
    "    raw_probs = tf.multiply(tf.nn.softmax(branch1_layer), branch_masks)\n",
    "    normalized_probs = tf.divide(raw_probs, tf.reduce_sum(raw_probs, 1, True))\n",
    "    normalized_logits = tf.concat(tf.log(normalized_probs), 1)\n",
    "    normalized_logits = tf.squeeze(normalized_logits, axis=0)\n",
    "    normalized_logits = tf.identity(normalized_logits, name=\"action\")\n",
    "    \n",
    "    init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of nodes to export for brain :Brain name\n",
      "\tversion_number\n",
      "\tmemory_size\n",
      "\tis_continuous_control\n",
      "\taction_output_shape\n",
      "\taction\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "settings = SerializationSettings(\"./models\", \"Brain name\", convert_to_barracuda=True, convert_to_onnx=False)\n",
    "frozen_graph_def = _make_frozen_graph(settings, graph, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_graph_def_path = settings.model_path + \"/frozen_graph_def.pb\"\n",
    "with gfile.GFile(frozen_graph_def_path, \"wb\") as f:\n",
    "    f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./models/frozen_graph_def.pb to ./models/model.nn\n",
      "IGNORED: Pack unknown layer\n",
      "GLOBALS: 'version_number', 'memory_size', 'is_continuous_control', 'action_output_shape'\n",
      "IN: 'action_masks': [-1, 1, 1, 1] => 'strided_slice'\n",
      "IN: 'vector_observation': [-1, 1, 1, 1] => 'dense/BiasAdd'\n",
      "OUT: 'concat/concat', 'action'\n",
      "DONE: wrote ./models/model.nn file.\n"
     ]
    }
   ],
   "source": [
    "tf2bc.convert(frozen_graph_def_path, settings.model_path + \"/model.nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, NamedTuple\n",
    "\n",
    "POSSIBLE_OUTPUT_NODES = frozenset([\"action\", \"action_probs\", \"recurrent_out\", \"value_estimate\"])\n",
    "MODEL_CONSTANTS = frozenset([\"action_output_shape\", \"is_continuous_control\", \"memory_size\", \"version_number\"])\n",
    "\n",
    "class SerializationSettings(NamedTuple):\n",
    "    model_path: str\n",
    "    brain_name: str\n",
    "    convert_to_barracuda: bool = True\n",
    "    convert_to_onnx: bool = True\n",
    "    onnx_opset: int = 9\n",
    "\n",
    "def _make_frozen_graph(settings: SerializationSettings, graph: tf.Graph, sess: tf.Session) -> tf.GraphDef:\n",
    "    with graph.as_default():\n",
    "        target_nodes = \",\".join(_process_graph(settings, graph))\n",
    "        graph_def = graph.as_graph_def()\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, target_nodes.replace(\" \", \"\").split(\",\"))\n",
    "    return output_graph_def\n",
    "\n",
    "def _process_graph(settings: SerializationSettings, graph: tf.Graph) -> List[str]:\n",
    "    \"\"\"\n",
    "    Gets the list of the output nodes present in the graph for inference\n",
    "    :return: list of node names\n",
    "    \"\"\"\n",
    "    all_nodes = [x.name for x in graph.as_graph_def().node]\n",
    "    nodes = [x for x in all_nodes if x in POSSIBLE_OUTPUT_NODES | MODEL_CONSTANTS]\n",
    "    print(\"List of nodes to export for brain :\" + settings.brain_name)\n",
    "    for n in nodes:\n",
    "        print(\"\\t\" + n)\n",
    "    return nodes\n",
    "\n",
    "def generate_session_config() -> tf.ConfigProto:\n",
    "    \"\"\"\n",
    "    Generate a ConfigProto to use for ML-Agents that doesn't consume all of the GPU memory\n",
    "    and allows for soft placement in the case of multi-GPU.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    # For multi-GPU training, set allow_soft_placement to True to allow\n",
    "    # placing the operation into an alternative device automatically\n",
    "    # to prevent from exceptions if the device doesn't suppport the operation\n",
    "    # or the device does not exist\n",
    "    config.allow_soft_placement = True\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
